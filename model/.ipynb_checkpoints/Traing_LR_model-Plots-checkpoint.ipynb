{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c3960b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Provide image size\n",
    "IMAGE_SIZE = [224, 224]\n",
    "\n",
    "# Give our training and testing path\n",
    "training_data = r'/Users/aruni/VScode_Workspace/project/breast_xray/train'\n",
    "testing_data = r'/Users/aruni/VScode_Workspace/project/breast_xray/test'\n",
    "\n",
    "# Find how many classes are present in the train dataset\n",
    "folders = glob(r'/Users/aruni/VScode_Workspace/project/breast_xray/train/*')\n",
    "\n",
    "# Logistic Regression Model\n",
    "input_shape = IMAGE_SIZE + [3]\n",
    "model = tf.keras.Sequential([\n",
    "    Flatten(input_shape=input_shape),\n",
    "    Dense(len(folders), activation='softmax')  # Output layer with softmax for multiclass classification\n",
    "])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c677e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_2 (Flatten)         (None, 150528)            0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 301058    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 301058 (1.15 MB)\n",
      "Trainable params: 301058 (1.15 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Found 497 images belonging to 2 classes.\n",
      "Found 491 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# View the structure of the model\n",
    "model.summary()\n",
    "\n",
    "# Compiling our model\n",
    "model.compile(\n",
    "  loss='categorical_crossentropy',\n",
    "  optimizer='adam',\n",
    "  metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# ImageDataGenerators\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "# Set up the data generators\n",
    "training_set = train_datagen.flow_from_directory(training_data,\n",
    "                                                 target_size = IMAGE_SIZE,\n",
    "                                                 batch_size = 10,\n",
    "                                                 class_mode = 'categorical')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(testing_data,\n",
    "                                            target_size = IMAGE_SIZE,\n",
    "                                            batch_size = 10,\n",
    "                                            class_mode = 'categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a509689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "50/50 [==============================] - 11s 221ms/step - loss: 6.5401 - accuracy: 0.7666 - val_loss: 6.3984 - val_accuracy: 0.7862\n",
      "Epoch 2/5\n",
      "50/50 [==============================] - 11s 215ms/step - loss: 5.5849 - accuracy: 0.7284 - val_loss: 1.6528 - val_accuracy: 0.7210\n",
      "Epoch 3/5\n",
      "50/50 [==============================] - 10s 209ms/step - loss: 3.0960 - accuracy: 0.7565 - val_loss: 2.1284 - val_accuracy: 0.7902\n",
      "Epoch 4/5\n",
      "50/50 [==============================] - 10s 210ms/step - loss: 3.4422 - accuracy: 0.7304 - val_loss: 1.8082 - val_accuracy: 0.7678\n",
      "Epoch 5/5\n",
      "50/50 [==============================] - 10s 209ms/step - loss: 5.6514 - accuracy: 0.7525 - val_loss: 6.1753 - val_accuracy: 0.7963\n"
     ]
    }
   ],
   "source": [
    "# Fitting the model\n",
    "r = model.fit(\n",
    "  training_set,\n",
    "  validation_data=test_set,\n",
    "  epochs=5, # Change the number of epochs if needed\n",
    "  steps_per_epoch=len(training_set),\n",
    "  validation_steps=len(test_set)\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "model.save('logistic_regression_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cfa1d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
