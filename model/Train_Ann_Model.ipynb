{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ec1d736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 150528)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              154141696 \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               524800    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 154667522 (590.01 MB)\n",
      "Trainable params: 154667522 (590.01 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Found 497 images belonging to 2 classes.\n",
      "Found 491 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Provide image size\n",
    "IMAGE_SIZE = [224, 224]\n",
    "\n",
    "# Give our training and testing path\n",
    "training_data = r'/Users/aruni/VScode_Workspace/project/breast_xray/train'\n",
    "testing_data = r'/Users/aruni/VScode_Workspace/project/breast_xray/test'\n",
    "\n",
    "# Find how many classes are present in the train dataset\n",
    "folders = glob(r'/Users/aruni/VScode_Workspace/project/breast_xray/train/*')\n",
    "\n",
    "# ANN Model\n",
    "input_shape = IMAGE_SIZE + [3]\n",
    "model = tf.keras.Sequential([\n",
    "    Flatten(input_shape=input_shape),\n",
    "    Dense(1024, activation='relu'),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(len(folders), activation='softmax')\n",
    "])\n",
    "\n",
    "# View the structure of the model\n",
    "model.summary()\n",
    "\n",
    "# Compiling our model\n",
    "model.compile(\n",
    "  loss='categorical_crossentropy',\n",
    "  optimizer='adam',\n",
    "  metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# ImageDataGenerators\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "# Set up the data generators\n",
    "training_set = train_datagen.flow_from_directory(training_data,\n",
    "                                                 target_size = IMAGE_SIZE,\n",
    "                                                 batch_size = 10,\n",
    "                                                 class_mode = 'categorical')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(testing_data,\n",
    "                                            target_size = IMAGE_SIZE,\n",
    "                                            batch_size = 10,\n",
    "                                            class_mode = 'categorical')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "649fa998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "50/50 [==============================] - 78s 2s/step - loss: 10.4701 - accuracy: 0.8431 - val_loss: 2.3330 - val_accuracy: 0.9124\n",
      "Epoch 2/5\n",
      "50/50 [==============================] - 78s 2s/step - loss: 2.1440 - accuracy: 0.8551 - val_loss: 0.3862 - val_accuracy: 0.9104\n",
      "Epoch 3/5\n",
      "50/50 [==============================] - 70s 1s/step - loss: 1.4920 - accuracy: 0.8672 - val_loss: 0.9675 - val_accuracy: 0.9124\n",
      "Epoch 4/5\n",
      "50/50 [==============================] - 40s 801ms/step - loss: 1.1945 - accuracy: 0.8632 - val_loss: 0.6043 - val_accuracy: 0.8921\n",
      "Epoch 5/5\n",
      "50/50 [==============================] - 63s 1s/step - loss: 1.1145 - accuracy: 0.8853 - val_loss: 0.3883 - val_accuracy: 0.9124\n"
     ]
    }
   ],
   "source": [
    "# Fitting the model\n",
    "r = model.fit(\n",
    "  training_set,\n",
    "  validation_data=test_set,\n",
    "  epochs=5, # Change the number of epochs if needed\n",
    "  steps_per_epoch=len(training_set),\n",
    "  validation_steps=len(test_set)\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "model.save('ann_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
